{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90809c8",
   "metadata": {},
   "source": [
    "# Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "992b8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ebb25",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29636eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info=tfds.load(name=\"mnist\", with_info=True, as_supervised=True)\n",
    "mnist_train,mnist_test=mnist_dataset[\"train\"], mnist_dataset[\"test\"]\n",
    "num_validation_samples=0.1*mnist_info.splits[\"train\"].num_examples\n",
    "num_validation_samples=tf.cast(num_validation_samples, tf.int64)\n",
    "num_test_samples=mnist_info.splits[\"test\"].num_examples\n",
    "num_test_samples=tf.cast(num_test_samples,tf.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cac0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image,label):\n",
    "    image=tf.cast(image, tf.float32)\n",
    "    image/=255.\n",
    "    return image,label\n",
    "\n",
    "scaled_train_and_validation_data=mnist_train.map(scale)\n",
    "test_data=mnist_test.map(scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e53608",
   "metadata": {},
   "source": [
    "# Permute the data in case it is sorted\n",
    "This is useful because if the data is ordered in a particular way, it can bias the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd365400",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE=10000\n",
    "shuffled_train_and_validation_data=scaled_train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8041791c",
   "metadata": {},
   "source": [
    "# Extract  validation and training data\n",
    "We create our train and validation data by taking a part of the original validation set. This is done since the Mnist original data doesn't have a set for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0ca6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data=shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data=shuffled_train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa664b7d",
   "metadata": {},
   "source": [
    "# Splitting the sets into batches\n",
    "we need to split the train data into batches in order to do batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dede4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=100\n",
    "train_data=train_data.batch(BATCH_SIZE)\n",
    "validation_data=validation_data.batch(num_validation_samples)\n",
    "test_data=test_data.batch(num_test_samples)\n",
    "validation_inputs,validation_targets=next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696168ea",
   "metadata": {},
   "source": [
    "## Model\n",
    "The mnist data set is a set of imagenes that can be consider as 28x28 squere matrices. We want to use machine learning to clasify the mnist data set as one of the 10 possible digits from 0 to 9. We will use 2 hidden layers of size 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ad30236",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=784\n",
    "output_size=10\n",
    "hidden_layer_size=50\n",
    "model=tf.keras.Sequential([\n",
    "                        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                        tf.keras.layers.Dense(hidden_layer_size, activation=\"relu\"),\n",
    "                        tf.keras.layers.Dense(hidden_layer_size, activation=\"relu\"),\n",
    "                        tf.keras.layers.Dense(output_size, activation=\"softmax\")\n",
    "    \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfbe7c7",
   "metadata": {},
   "source": [
    "# Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d87fcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37fed0a",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a24e9390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 6s - loss: 0.4085 - accuracy: 0.8820 - val_loss: 0.2019 - val_accuracy: 0.9400 - 6s/epoch - 12ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 3s - loss: 0.1701 - accuracy: 0.9500 - val_loss: 0.1487 - val_accuracy: 0.9560 - 3s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 2s - loss: 0.1312 - accuracy: 0.9614 - val_loss: 0.1311 - val_accuracy: 0.9603 - 2s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 2s - loss: 0.1090 - accuracy: 0.9676 - val_loss: 0.1102 - val_accuracy: 0.9673 - 2s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.0933 - accuracy: 0.9720 - val_loss: 0.0920 - val_accuracy: 0.9728 - 3s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2192b3fc850>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS=5\n",
    "model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs,validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f4976",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "We need to test the model with a set that the algorithm havenÂ´t seen before to deal with the **Overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c171c204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1021 - accuracy: 0.9682\n",
      "Test lost: 0.10. Test accuracy: 96.82%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy=model.evaluate(test_data)\n",
    "print('Test lost: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss,test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c8d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jian",
   "language": "python",
   "name": "py3-tf2.00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
